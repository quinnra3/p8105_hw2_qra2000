---
title: "p8105_hw2_qra2000"
output: github_document
date: "2023-09-26"
---

```{r load_libraries, include = FALSE}
library(tidyverse)
library(readxl)
library(dplyr)
```

## Problem 1

First, clean the data in `pols-month.csv`. Use `separate()` to break up the variable `mon` into integer variables `year`, `month`, and `day`; replace `month number` with `month name`; create a president variable taking values `gop` and `dem`, and remove `prez_dem` and `prez_gop`; and remove the `day` variable.

```{r clean_538_pols, results='hide'}
month_df = 
  tibble(
    month_num = 1:12,
    month_abb = month.abb,
    month = month.name
  )

pols = 
  read_csv("./data/fivethirtyeight_datasets/pols-month.csv") |>
  separate(mon, into = c("year", "month_num", "day"), convert = TRUE) |>
  mutate(
    president = recode(prez_gop, "0" = "dem", "1" = "gop", "2" = "gop")) |>
  left_join(x = _, y = month_df) |> 
  select(year, month, everything(), -day, -starts_with("prez"))
```

Second, clean the data in `snp.csv` using a similar process to the above. For consistency across datasets, arrange according to `year` and `month`, and organize so that `year` and `month` are the leading columns.

```{r clean_538_snp, results='hide'}
snp = 
  read_csv("./data/fivethirtyeight_datasets/snp.csv") |>
  separate(date, into = c("month", "day", "year"), convert = TRUE) |>
  arrange(year, month) |>
  mutate(month = month.name[month]) |>
  select(year, month, close) 
```

Third, tidy the unemployment data so that it can be merged with the previous datasets. This process will involve switching from “wide” to “long” format; ensuring that key variables have the same name; and ensuring that key variables take the same values.

```{r clean_538_unemp, results='hide'}
unemployment = 
  read_csv("./data/fivethirtyeight_datasets/unemployment.csv") |>
  rename(year = Year) |>
  pivot_longer(
    Jan:Dec, 
    names_to = "month_abb",
    values_to = "unemployment"
  ) |> 
  left_join(x = _, y = month_df) |> 
  select(year, month, unemployment)
```

Join the datasets by merging snp into pols, and merging unemployment into the result.

```{r merge_538, results='hide'}
data_538 = 
  left_join(pols, snp) |>
  left_join(x = _, y = unemployment)

str(data_538)
```

## Problem 2

Read and clean the Mr. Trash Wheel sheet:
*specify the sheet in the Excel file and to omit non-data entries (rows with notes / figures; columns containing notes) using arguments in `read_excel`
*use reasonable variable names
*omit rows that do not include dumpster-specific data

The data include a column for the (approximate) number of homes powered. This calculation is described in the Homes powered note, but not applied to every row in the dataset. Update the data to include a new homes_powered variable based on this calculation.

```{r clean_mr_trash}
mr_trash_df = 
  read_xlsx(
    "./data/202309 Trash Wheel Collection Data.xlsx",
    sheet = "Mr. Trash Wheel",
    skip = 1)|> 
  janitor::clean_names() |> 
  drop_na(dumpster) |> 
  select(-x15, -x16) |> 
  mutate(
    homes_powered = (weight_tons*500)/30,
    year = as.numeric(year)
    )
```

Next, import, clean, and organize the data for Professor Trash Wheel and Gwynnda. 

```{r clean_prof_trash_wheel and gwynnda_trash_wheel}
prof_trash_wheel_df = 
  read_xlsx(
    "./data/202309 Trash Wheel Collection Data.xlsx",
    sheet = "Professor Trash Wheel",
    skip = 1)|> 
  janitor::clean_names() |> 
  drop_na(dumpster) |> 
  mutate(
    homes_powered = (weight_tons*500)/30,
    year = as.numeric(year),
    trash_wheel_name = "Professor Trash Wheel",
  )

gwynnda_df = 
  read_xlsx(
    "./data/202309 Trash Wheel Collection Data.xlsx",
    sheet = "Gwynnda Trash Wheel",
    skip = 1)|> 
  janitor::clean_names() |> 
  drop_na(dumpster) |> 
  mutate(
    homes_powered = (weight_tons*500)/30,
    year = as.numeric(year)
  )
```

Combine the Professor Trash Wheel, Gwynnda, and Mr. Trash Wheel datasets to produce a single tidy dataset.

```{r combine_trash_wheel_data}
trash_wheel_data = 
  bind_rows(mr_trash_df, prof_trash_wheel_df, gwynnda_df)

view(trash_wheel_data)
```

The Mr. Trash Wheel, Professor Trash Wheel, and Gwynnda Trash Wheel datasets are sourced from a publicly available excel spreadsheet that details information about the trash collected by the water wheel trash collecting vessles in Baltimore, Maryland. There are `r ncol(trash_wheel_data)` variables in the dataset that combines the data from Mr. Trash Wheel, Professor Trash Wheel, and Gwynnda Trash Wheel. The descriptive variables include the combined dataset include the dumpster number, month, year, and date of the trash that was collected. It also includes the weight in tons and volume in cubic yards. The dataset also includes the total of each type of trash collected, separated into plastic bottles, polystrene, cigarette butts, glass bottles, plastic bags, wrappers, and sport balls. It also includes the calculation of homes powered by the weight (in tons) of trash collected. There are `r nrow(trash_wheel_data)` observations in the combined dataset. There are a number of key observations that can be drawn from this dataset. For example, the total weight of trash Professor Trash Wheel collected is `r subset(trash_wheel_data, trash_wheel_name == "Professor Trash Wheel") |> pull(weight_tons) |> sum()` tons. The total number of cigarette butts collected by Gwynnda in July of 2021 is `r subset(gwynnda_df, year == 2021 & month == "July") |> pull(cigarette_butts) |> sum() |> as.integer()`. 


## Problem 3

Import, clean, and tidy the dataset of baseline demographics. Ensure that sex and AOE4 carrier status are appropriate encoded (i.e. not numeric), and remove any participants who do not meet the stated inclusion criteria (i.e. no MCI at baseline).

```{r}
MCI_baseline_clean = 
  read.csv("./data/data_mci/MCI_baseline.csv",
           skip = 1) |> 
  janitor::clean_names() |>
  mutate(
    sex = case_match(
      sex,
      1 ~ "male",
      0 ~ "female"),
    apoe4 = case_match(
      apoe4,
      1 ~ "APOE4 carrier",
      0 ~ "APOE4 non-carrier",)) |> 
  filter(age_at_onset != ".")
```

The key steps to importing the baseline demographics dataset are first reading the .csv file to R and cleaning the variable names. Then, to ensure that the variables `sex` and `aoe4` are appropriately encoded, use `case_match()` to add dichotomous, meaningful labels according to each. For example, assign "1" for "male", and "1" for "AOE4 carrier". To remove any participants who did not meet the sufficient inclusion criteria for this study, they are filtered out of the dataset using the `filter(!=)` function. 

There are `r ncol(MCI_baseline_clean)` variables included in the baseline demographics dataset, including id, sex, education, current age, APOE4 carrier status (yes/no), and age of MCI onset. The number of participants recruited are `r nrow(MCI_baseline_clean)` with an average age of `r mean(pull(MCI_baseline_clean, current_age))`. During the course of the follow-up period, `r filter(MCI_baseline_clean, age_at_onset != ".") |> nrow()` participants developed MCI. The proportion of women who are APOE4 carriers is `r scales::percent(nrow(filter(MCI_baseline_clean, sex == "female" & apoe4 == "carrier")) / nrow(filter(MCI_baseline_clean, sex == "female")))`.

Import, clean, and tidy the dataset of longitudinally observed biomarker values.

```{r}
MCI_amyloid_clean = 
  read.csv("./data/data_mci/mci_amyloid.csv",
           skip = 1) |> 
  janitor::clean_names() |> 
  mutate(id = `study_id`) |> 
  select(-study_id) |> 
  na.omit(MCI_amyloid_clean)

view(MCI_amyloid_clean)
```
The key steps to importing the longitudinal amyloid observed dataset are first reading in the .csv file to R and cleaning the variable names. Then, rename the variable `study_id` to `id` using the `mutate` function to ensure compatibility with the baseline MCI dataset. NA values are removed using the `na.omit` function. This dataset describes the amyloid β 42/40 ratio over a period of five times for each eligible study participant: baseline, time_2, time_4, time_6, and time_8. The amyloid longitudinal dataset has a total of `r nrow(MCI_amyloid_clean)` participants. 

To check whether some participants appear in only the baseline or amyloid datasets, first merge the amyloid longitudinal dataset with the baseline to keep all participants in both datasets.

```{r}
MCI_full_join = 
  full_join(MCI_baseline_clean, MCI_amyloid_clean, by = c("id"))
```

There are `r nrow(MCI_full_join) - nrow(MCI_baseline_clean)` participants in the baseline set but not amyloid. Conversely, there are `r nrow(MCI_full_join) - nrow(MCI_amyloid_clean)` participants in amyloid but not baseline. There are more participants missing from the amyloid longitudinal dataset because longitudinal studies are difficult to maintain retention from study participants, as they take place over a long period of time. 

Next, combine the demographic and biomarker datasets so that only participants who appear in both datasets are retained, and briefly describe the resulting dataset. 

```{r}
MCI_combined_data = inner_join(MCI_baseline_clean, MCI_amyloid_clean, by = c("id"))
```

The dataset combining both the demographic and biomarker datasets that includes only participants who appear in both has variables `r ncol(MCI_combined_data)` variables, combining the variables from the longitudinal dataset to the baseline dataset. There are a total of `r nrow(MCI_combined_data)` participants in the combined dataset, with an average age of `r mean(pull(MCI_combined_data, current_age))`.

Export the result as a CSV to the data directory. 

```{r}
write.csv(MCI_combined_data, "results/MCI Combined Data.csv")
```















