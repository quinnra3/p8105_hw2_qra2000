---
title: "p8105_hw2_qra2000"
output: github_document
date: "2023-09-26"
---

```{r load_libraries, include = FALSE}
library(tidyverse)
library(readxl)
library(dplyr)
```

## Problem 1

First, clean the data in `pols-month.csv`. Use `separate()` to break up the variable `mon` into integer variables `year`, `month`, and `day`; replace `month number` with `month name`; create a president variable taking values `gop` and `dem`, and remove `prez_dem` and `prez_gop`; and remove the `day` variable.

```{r clean_538_pols}
month_df = 
  tibble(
    month_num = 1:12,
    month_abb = month.abb,
    month = month.name
  )

pols = 
  read_csv("./data/fivethirtyeight_datasets/pols-month.csv") |>
  separate(mon, into = c("year", "month_num", "day"), convert = TRUE) |>
  mutate(
    president = recode(prez_gop, "0" = "dem", "1" = "gop", "2" = "gop")) |>
  left_join(x = _, y = month_df) |> 
  select(year, month, everything(), -day, -starts_with("prez"))
```

Second, clean the data in `snp.csv` using a similar process to the above. For consistency across datasets, arrange according to `year` and `month`, and organize so that `year` and `month` are the leading columns.

```{r clean_538_snp}
snp = 
  read_csv("./data/fivethirtyeight_datasets/snp.csv") |>
  separate(date, into = c("month", "day", "year"), convert = TRUE) |>
  arrange(year, month) |>
  mutate(month = month.name[month]) |>
  select(year, month, close) 
```

Third, tidy the unemployment data so that it can be merged with the previous datasets. This process will involve switching from “wide” to “long” format; ensuring that key variables have the same name; and ensuring that key variables take the same values.

```{r clean_538_unemp}
unemployment = 
  read_csv("./data/fivethirtyeight_datasets/unemployment.csv") |>
  rename(year = Year) |>
  pivot_longer(
    Jan:Dec, 
    names_to = "month_abb",
    values_to = "unemployment"
  ) |> 
  left_join(x = _, y = month_df) |> 
  select(year, month, unemployment)
```

Join the datasets by merging snp into pols, and merging unemployment into the result.

```{r merge_538}
data_538 = 
  left_join(pols, snp) |>
  left_join(x = _, y = unemployment)

str(data_538)
```

## Problem 2

Read and clean the Mr. Trash Wheel sheet:
*specify the sheet in the Excel file and to omit non-data entries (rows with notes / figures; columns containing notes) using arguments in `read_excel`
*use reasonable variable names
*omit rows that do not include dumpster-specific data

The data include a column for the (approximate) number of homes powered. This calculation is described in the Homes powered note, but not applied to every row in the dataset. Update the data to include a new homes_powered variable based on this calculation.

```{r clean_mr_trash}
mr_trash_df = 
  read_xlsx(
    "./data/202207 Trash Wheel Collection Data.xlsx",
    sheet = "Mr. Trash Wheel",
    skip = 1)|> 
  janitor::clean_names() |> 
  drop_na(dumpster) |> 
  mutate(
    homes_powered = (weight_tons*500)/30,
    mr_trash_wheel = "Mr Trash Wheel Data",
    year = as.numeric(year)
  )
  
mr_trash_df
```

Next, import, clean, and organize the data for Professor Trash Wheel and Gwynnda. 

```{r clean_prof_trash_wheel}
prof_trash_wheel_df = 
  read_xlsx(
    "./data/202207 Trash Wheel Collection Data.xlsx",
    sheet = "Professor Trash Wheel",
    skip = 1)|> 
  janitor::clean_names() |> 
  drop_na(dumpster) |> 
  mutate(
    homes_powered = (weight_tons*500)/30,
    prof_trash_wheel = "Professor Trash Wheel",
    year = as.numeric(year)
  )

prof_trash_wheel_df
```

```{r clean_gwynnda}
gwynnda_df = 
  read_xlsx(
    "./data/202207 Trash Wheel Collection Data.xlsx",
    sheet = "Gwynnda Trash Wheel",
    skip = 1)|> 
  janitor::clean_names() |> 
  drop_na(dumpster) |> 
  mutate(
    homes_powered = (weight_tons*500)/30,
    gwynnda_trash_wheel = "Gywnnda Trash Wheel",
    year = as.numeric(year)
  )

gwynnda_df
```

Combine the Professor Trash Wheel, Gwynda, and Mr. Trash Wheel datasets to produce a single tidy dataset.

```{r}
trash_wheel_data = 
  bind_rows(mr_trash_df, prof_trash_wheel_df, gwynnda_df)

trash_wheel_data
```

[insert description here:



total weight of trash collected by Professor Trash Wheel -> 190.12

total number of cigarette butts collected by Gwynnda in July of 2021 -> 16,300

]

## Problem 3

Import, clean, and tidy the dataset of baseline demographics. Ensure that `sex` and `APOE4` carrier status are appropriate encoded (i.e. not numeric), and remove any participants who do not meet the stated inclusion criteria (i.e. no MCI at baseline).

```{r}
MCI_baseline_clean = 
  read.csv("./data/data_mci/MCI_baseline.csv",
           skip = 1) |> 
  janitor::clean_names() |>
  mutate(
    sex = case_match(
      sex,
      1 ~ "male",
      0 ~ "female",
    ),
    apoe4 = case_match(
      apoe4,
      1 ~ "APOE4 carrier",
      0 ~ "APOE4 non-carrier"
    )
  )
  filter(MCI_baseline_clean, age_at_onset != ".")

MCI_baseline_clean
```

Discuss important steps in the import process and relevant features of the dataset:

How many participants were recruited, and of these how many develop MCI? What is the average baseline age? What proportion of women in the study are APOE4 carriers?
- total `id` = 483 
- of the participants recuirted, 97 developed MCI.
- average baseline age = 65.04679. 
- 63 women in the study are APOE4 carriers

```{r}
select(MCI_baseline_clean, id)

filter(MCI_baseline_clean, age_at_onset != ".")

mean(pull(MCI_baseline_clean, current_age))

filter(MCI_baseline_clean, sex != "male", apoe4 != "APOE4 non-carrier")
```

Import, clean, and tidy the dataset of longitudinally observed biomarker values:

```{r}
MCI_amyloid_clean = 
  read.csv("./data/data_mci/mci_amyloid.csv",
           skip = 1) |> 
  janitor::clean_names() |> 
  mutate(id = `study_id`) |> 
  select(-study_id) |> 
  na.omit(MCI_amyloid_clean)

MCI_amyloid_clean
```

[Comment on the steps on the import process and the features of the dataset:

`study_id` is conditional and is duplicate in the .csv file, so that `study_id` corresponds to individual 


]

Check whether some participants appear in only the baseline or amyloid datasets, and comment on your findings. Combine the demographic and biomarker datasets so that only participants who appear in both datasets are retained, and briefly describe the resulting dataset; export the result as a CSV to your data directory.

```{r}
MCI_combined_data = inner_join(MCI_baseline_clean, MCI_amyloid_clean)
nrow(MCI_combined_data)

write.csv(MCI_combined_data, "results/MCI Combined Data.csv")
```













